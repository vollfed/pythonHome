{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!... finally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "msg = tf.constant('Hello, TensorFlow!... finally')\n",
    "tf.print(msg)\n",
    "\n",
    "%matplotlib inline\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import reduce\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ['id', 'url_legal', 'license', 'excerpt','target','standard_error']\n",
    "data_train = pd.read_csv('train.csv', sep=',',\n",
    "                         error_bad_lines=False, names=n,\n",
    "                         quotechar='\"',skipinitialspace=True,\n",
    "                         usecols=['excerpt','standard_error','target'],skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.649671297\n",
      "0.0\n",
      "0.49143509098976706\n"
     ]
    }
   ],
   "source": [
    "# zipf freq is basicaly log_10(freq * 10^9) = 9 + log_10(freq)\n",
    "# i.e zipf = 6 is once per 1000\n",
    "# 9 + log10(1/1000) = 6\n",
    "\n",
    "zipf_frequency('ubiquitous', 'en')\n",
    "print(data_train['standard_error'].max())\n",
    "print(data_train['standard_error'].min())\n",
    "print(data_train['standard_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when young people returned ballroom presented decidedly changed appearance instead interior scene winter landscape floor covered with snow white canvas laid smoothly rumpled over bumps hillocks like real snow field numerous palms evergreens that decorated room were powdered with flour strewn with tufts cotton like snow also diamond dust been lightly sprinkled them glittering crystal icicles hung from branches each room wall hung beautiful bear skin these rugs were prizes girls boys this game girls were gathered room boys other called north pole other south pole each player given small flag which they were plant reaching pole this would have been easy matter each traveller obliged wear snowshoes\n",
      "[6.37, 5.43, 6.25, 4.82, 3.52, 4.75, 3.37, 5.07, 4.69, 5.24, 4.55, 4.97, 4.89, 4.36, 4.94, 4.83, 6.85, 4.66, 5.51, 3.96, 4.56, 3.68, 2.24, 6.08, 3.6, 1.96, 6.41, 5.6, 4.66, 5.24, 4.65, 3.55, 2.33, 7.01, 3.94, 5.39, 6.34, 3.31, 6.85, 4.0, 3.08, 6.85, 3.1, 4.35, 6.41, 4.66, 6.19, 4.42, 4.41, 6.27, 3.96, 3.24, 6.19, 3.19, 4.4, 2.41, 4.21, 6.63, 4.21, 5.69, 5.39, 5.04, 4.21, 5.22, 4.71, 4.91, 6.04, 3.19, 6.34, 4.01, 5.17, 5.03, 6.82, 5.72, 5.17, 6.34, 4.27, 5.39, 5.03, 6.16, 5.59, 5.34, 4.23, 6.16, 5.4, 4.23, 5.69, 5.19, 5.41, 5.51, 4.58, 6.3, 6.5, 6.34, 4.89, 4.46, 4.23, 6.82, 6.27, 6.71, 6.27, 5.29, 5.38, 5.69, 3.49, 3.77, 4.92, 2.25]\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[\\n,.-]+', ' ', text)\n",
    "    text = re.sub(r'\\b[a-z]{,3}\\b', ' ', text)\n",
    "    text = text = re.sub(r'[\\s]+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def get_freq_list(text):\n",
    "    return list( map(lambda x: zipf_frequency(x, 'en') , text.split(\" \")))\n",
    "     \n",
    "def get_excerpt_cmplx(freq_list):\n",
    "    return reduce(lambda x, y:  x + ( 1 if y <= 4 else 0), freq_list,0)\n",
    "\n",
    "data_train['excerpt'][0]\n",
    "text1 = data_train['excerpt'][0]\n",
    "text1 = preprocess_text(text1)\n",
    "print(text1)\n",
    "freq_list = get_freq_list(text1)\n",
    "print(freq_list)\n",
    "\n",
    "res = get_excerpt_cmplx(freq_list)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'When the young people returned to the ballroom, it presented a decidedly changed appearance. Instead of an interior scene, it was a winter landscape.\\nThe floor was covered with snow-white canvas, not laid on smoothly, but rumpled over bumps and hillocks, like a real snow field. The numerous palms and evergreens that had decorated the room, were powdered with flour and strewn with tufts of cotton, like snow. Also diamond dust had been lightly sprinkled on them, and glittering crystal icicles hung from the branches.\\nAt each end of the room, on the wall, hung a beautiful bear-skin rug.\\nThese rugs were for prizes, one for the girls and one for the boys. And this was the game.\\nThe girls were gathered at one end of the room and the boys at the other, and one end was called the North Pole, and the other the South Pole. Each player was given a small flag which they were to plant on reaching the Pole.\\nThis would have been an easy matter, but each traveller was obliged to wear snowshoes.'\n",
    "text3 = 'When the not young \\npeople returned to the ballroom, it presented a'\n",
    "\n",
    "cols = ['dot','com','wcnt','text','cmpl']\n",
    "df = pd.DataFrame(columns=cols)  \n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    text = data_train['excerpt'][i]\n",
    "    processed_text = preprocess_text(text)\n",
    "    df = df.append({\n",
    "         \"dot\": text.count('.'),\n",
    "         \"com\":  text.count(','),\n",
    "         \"text\": processed_text,\n",
    "         \"wcnt\": len(text.split()),\n",
    "         \"cmpl\": get_excerpt_cmplx(get_freq_list(processed_text))\n",
    "          }, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dot                                                    11\n",
       "com                                                    14\n",
       "wcnt                                                  179\n",
       "text    when young people returned ballroom presented ...\n",
       "cmpl                                                   22\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot</th>\n",
       "      <th>com</th>\n",
       "      <th>wcnt</th>\n",
       "      <th>text</th>\n",
       "      <th>cmpl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>179</td>\n",
       "      <td>when young people returned ballroom presented ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>169</td>\n",
       "      <td>through dinner time fayre somewhat silent eyes...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>166</td>\n",
       "      <td>roger predicted snow departed quickly came day...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>164</td>\n",
       "      <td>outside before palace great garden walled roun...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>147</td>\n",
       "      <td>once upon time there were three bears lived to...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>145</td>\n",
       "      <td>when think dinosaurs where they lived what pic...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>164</td>\n",
       "      <td>what solid ? solids usually hard because their...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>second state matter will discuss liquid solids...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>solids shapes that actually touch they have th...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>146</td>\n",
       "      <td>animals made many cells they things digest the...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dot com wcnt                                               text cmpl\n",
       "0     11  14  179  when young people returned ballroom presented ...   22\n",
       "1     10  24  169  through dinner time fayre somewhat silent eyes...   40\n",
       "2     11  17  166  roger predicted snow departed quickly came day...   34\n",
       "3      5  23  164  outside before palace great garden walled roun...   32\n",
       "4      5  13  147  once upon time there were three bears lived to...   11\n",
       "...   ..  ..  ...                                                ...  ...\n",
       "2829  10  12  145  when think dinosaurs where they lived what pic...   27\n",
       "2830  13   5  164  what solid ? solids usually hard because their...   20\n",
       "2831  16   2  190  second state matter will discuss liquid solids...   15\n",
       "2832  12   8  150  solids shapes that actually touch they have th...   24\n",
       "2833  13  23  146  animals made many cells they things digest the...   31\n",
       "\n",
       "[2834 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
      "[[ 5  6  7  8  9]\n",
      " [15 16 17 18 19]]\n"
     ]
    }
   ],
   "source": [
    "# n = ['id', 'url_legal', 'license', 'excerpt','target','standard_error']\n",
    "# id,url_legal,license,excerpt,target,standard_error\n",
    "\n",
    "# data_positive = pd.read_csv('positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "# data_negative = pd.read_csv('negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "\n",
    "# sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
    "# raw_data = np.concatenate((data_positive['text'].values[:sample_size],\n",
    "#                            data_negative['text'].values[:sample_size]), axis=0)\n",
    "# labels = [1] * sample_size + [0] * sample_size\n",
    "# data_int = [preprocess_text(t) for t in raw_data]\n",
    "\n",
    "\n",
    "# length = [len(i) for i in data_int]\n",
    "# print(\"Average Review length:\", np.mean(length))\n",
    "# print(\"Standard Deviation:\", round(np.std(length)))\n",
    "SENTENCE_LENGTH = 5\n",
    "foo = [1,2]\n",
    "foo[0] = [ i for i in range(10)]\n",
    "foo[1] = [ i for i in range(10,20)]\n",
    "\n",
    "print(foo)    \n",
    "print(pad_sequences(foo, maxlen=SENTENCE_LENGTH)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LENGTH = 50\n",
    "NUM = 10000\n",
    "NUM_TEST = 50000\n",
    "\n",
    "def get_sequences(data_p):\n",
    "    sequences = tokenizer.texts_to_sequences(data_p)\n",
    "    return pad_sequences(sequences, maxlen=SENTENCE_LENGTH)\n",
    "\n",
    "#we will use only NUM top used words as comp nerezinovi\n",
    "def get_my_sequences(comment_p):\n",
    "    result = [index.get(str,1) for str in comment_p.split(' ') if index.get(str,1) < NUM]\n",
    "    return result\n",
    "\n",
    "def vectorize(sequences, dimension = NUM):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM,oov_token=\"#\")\n",
    "tokenizer.fit_on_texts(data_int[NUM:])\n",
    "\n",
    "index = tokenizer.word_index\n",
    "\n",
    "#Change words to indexes from vocabulary that we sdelali\n",
    "data = [get_my_sequences(comment) for comment in data_int]\n",
    "\n",
    "#Change to 0-1 index\n",
    "data = vectorize(data)\n",
    "targets = np.array(labels).astype(\"float32\")\n",
    "        \n",
    "#this is keras train/test it is with shuffle\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, labels, test_size=0.2, random_state=2)\n",
    "\n",
    "#test_x = data[:NUM_TEST]\n",
    "#test_y = targets[:NUM_TEST]\n",
    "\n",
    "#train_x = data[NUM_TEST:]\n",
    "#train_y = targets[NUM_TEST:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13866\n",
      "2892\n",
      "170145\n",
      "data:_____\n",
      "USER углу сидит погибает голода еще порции взяли хотя уже жрать не хотим\n",
      "[1, 5005, 759, 163604, 6285, 10, 16649, 1653, 97, 11, 889, 3, 2216]\n",
      "[1, 5005, 759, 6285, 10, 1653, 97, 11, 889, 3, 2216]\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "i=3\n",
    "strTest = \"USER углу сидит погибает голода еще порции взяли хотя уже жрать не хотим\"\n",
    "ttt1 = [index.get(str,1) for str in strTest.split(' ')]\n",
    "print(index.get('школота'))\n",
    "print(index.get('поверь'))\n",
    "print(len(index))\n",
    "\n",
    "print('data:_____')\n",
    "print(strTest)\n",
    "print(ttt1)\n",
    "print(get_my_sequences(strTest))\n",
    "print(data[i][0:60])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-3 is some magic.# replace when word not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                500050    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 505,201\n",
      "Trainable params: 505,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "# Input - Layer\n",
    "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "# Hidden - Layers\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "# Output- Layer\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 179076 samples, validate on 44770 samples\n",
      "Epoch 1/2\n",
      "179076/179076 [==============================] - 60s 336us/step - loss: 0.5735 - accuracy: 0.6967 - val_loss: 0.5330 - val_accuracy: 0.7306\n",
      "Epoch 2/2\n",
      "179076/179076 [==============================] - 64s 360us/step - loss: 0.4992 - accuracy: 0.7544 - val_loss: 0.5285 - val_accuracy: 0.7341\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(\n",
    " train_x, train_y,\n",
    " epochs= 2,\n",
    " batch_size = 500,\n",
    " validation_data = (test_x, test_y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7323542535305023\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results.history[\"val_accuracy\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "прекрасный наполненный смыслом и радостью фильм понравился очень\n",
      "этот фильм полный шлак посмотрел самый худший фильм видел оценка минус один нуля\n",
      "\n",
      "Get index \n",
      "\n",
      "[[1405, 1, 8683, 2385, 179, 936, 18]]\n",
      "[[68, 179, 1084, 784, 182, 6773, 179, 493, 5039, 1132, 82]]\n"
     ]
    }
   ],
   "source": [
    "testPositive = \"прекрасный наполненный смыслом и радостью фильм понравился очень\"\n",
    "testNegative = \"этот фильм полный шлак посмотрел самый худший фильм видел оценка минус один нуля\"\n",
    "\n",
    "print(testPositive)\n",
    "print(testNegative)\n",
    "\n",
    "testPositiveArr = [1]\n",
    "testNegativeArr = [1]\n",
    "\n",
    "print(\"\\n\"+\"Get index \"+\"\\n\")\n",
    "\n",
    "testPositiveArr[0] = get_my_sequences(testPositive)\n",
    "testNegativeArr[0] = get_my_sequences(testNegative)\n",
    "\n",
    "print(testPositiveArr)\n",
    "print(testNegativeArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.8635264\n",
      "Negative: 0.051291257\n"
     ]
    }
   ],
   "source": [
    "testPositiveArrINDX = vectorize(testPositiveArr)\n",
    "testNegativeArrINDX = vectorize(testNegativeArr)\n",
    "\n",
    "predictPositive = model.predict(testPositiveArrINDX)\n",
    "predictNegative = model.predict(testNegativeArrINDX)\n",
    "\n",
    "print('Positive: ' + str(predictPositive[0][0]))\n",
    "print('Negative: ' + str(predictNegative[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trainedModel.hdf5')\n",
    "df = pd.DataFrame.from_dict(index, orient=\"index\")\n",
    "df.to_csv(\"commentDict.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "309.85px",
    "left": "910px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
